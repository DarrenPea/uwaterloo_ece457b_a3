# Assignment 3

## Q1 Default Network

Following the requirements in the provided architecture, this is the summary of the model:

![q1 model summary](img/q1/summary.png)

### Training and Validation Accuracy vs Epochs

![accuracy vs epochs](img/q1/accuracy.png)

### Training and Validation Loss vs Epochs

![loss vs epochs](img/q1/loss.png)

### Test Accuracy

After training the model, it was evaluated with the test set.

![test accuracy](img/q1/test.png)

## Q2 Your Own Improvements

1. We introduced a validation set along with the training and test set by splitting the training set into 80% training, 20% validation. This would help the model to tune its hyperparameters while training, before testing its generalisation performance on the test set.

2. Image augmentation was performed to increase the diversity of the training data and its size.
	```
	data_augmentation = ImageDataGenerator(
		rotation_range=15,
		width_shift_range=0.15,
		height_shift_range=0.15,
		shear_range=0.1,
		zoom_range=0.2,
		horizontal_flip=True,
	)
	```

3. We tried out a new architecture for the model by introducting `BatchNormalization` to stabilise and accelerate the training process through the normalising of inputs to each layer. Secondly, we introduced `Dropout` layers to prevent overfitting, by dropping a fraction of nodes during training. Thirdly, we increased the number of filters for each layer so that it will be able to extract more features from the dataset. Lastly, we tried using Adam optimiser for better learning. 
	```
	def build_improved_cnn():
		model = keras.Sequential([
			layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), strides=1, padding='same', activation='relu'),
			layers.BatchNormalization(),
			layers.MaxPooling2D((2, 2)),
			layers.Dropout(0.15),

			layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu'),
			layers.BatchNormalization(),
			layers.MaxPooling2D((2, 2)),
			layers.Dropout(0.15),

			layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu'),
			layers.BatchNormalization(),
			layers.MaxPooling2D((2, 2)),
			layers.Dropout(0.15),

			layers.Flatten(),
			layers.Dense(512, activation='relu'),
			layers.BatchNormalization(),
			layers.Dropout(0.25),
			layers.Dense(5, activation='softmax')
		])

		model.compile(
			optimizer=keras.optimizers.Adam(learning_rate=3e-4),
			loss='categorical_crossentropy',
			metrics=['accuracy']	
		)

		return model
	```

4. We also implemented callbacks like `ReduceLROnPlateau` to adjust the learning rate dynamically, and `EarlyStopping` to stop training when `val_loss` stops improving and restores the best weights.

## Q3 Result Analysis
### Model summary
This is the summary of the model:

![q2 model summary](img/q2/summary1.png)
![q2 model summary](img/q2/summary2.png)

### Runtime analysis

||Base Network|Improved Network|
|------------|------------|----------------|
|**Training Runtime**|160.65 seconds|1467.06 seconds|
|**Testing Runtime**|2.67 seconds|3.32 seconds|

**Comments on Runtimes:**
The improved network takes significantly longer to train compared to the base network—about 10 times longer (1467.06 seconds vs. 160.65 seconds). This is expected because the improved model is deeper and more complex, with more convolutional layers, additional regularization (dropout and batch normalization), and the overhead of data augmentation. All these enhancements increase the number of operations and therefore the overall training time.

On the other hand, the testing (or inference) runtime only increases marginally (from 2.67 seconds to 3.32 seconds), which indicates that despite the added complexity, the model is still efficient enough for deployment. In many practical applications, inference speed is critical, and a small increase in testing time is often acceptable.

When judging whether the increased training runtime is worth the improvement in accuracy, we have to consider the following:
- **Accuracy Gains:** The improved network reaches a higher validation and test accuracy (around 98.4% compared to approximately 97.1% for the base network). This improvement of about 1–1.5% can be crucial in applications where even small improvements lead to better decision-making.
- **Model Robustness:** The additional layers, data augmentation, and regularization techniques not only boost accuracy but also help the model generalize better to unseen data, potentially reducing overfitting.
- **Deployment Considerations:** Since the inference time is only slightly affected, the extra training time does not negatively impact real-time performance.

Ultimately, if achieving higher predictive performance and improved robustness is the priority, then the increased training time is a worthwhile trade-off. That being said, should computation power or time be a significant limiting factor, we can settle for the base network as the gains in testing accuracy are marginal and might not be critical since the context of this problem is only classifying fashion images.


### Hyper parameters and designs used
In our improved network, we tweaked the base network to include the following changes:
1. Increased Network depth and Complexity
	- The improved network used a deeper and wider network with 3 convolutional blocks, each increasing the number of filters (64 --> 128 --> 258). This design helps the network learn more complex features at different levels of abstraction.
2. Regularization
	- The improved network uses Dropout in several layers (0.15 in conv blocks and 0.25 before the final dense layer) and Batch Normalization after each Conv2D and Dense layer. These techniques help stabilize training and prevent overfitting by reducing internal covariate shift and randomly dropping out a subset of neurons during training.
3. Data Augmentation
	- The improved network implements a robust data augmentation strategy using random rotations, shifts, shearing, zoom, and horizontal flipping. This increases the effective size and variability of the training set, allowing the model to generalize better to unseen data.
4. Optimizer and Learning Rates
	- The improved network uses the Adam optimizer with an initial learning rate of 3e-4, along with a learning rate scheduler (`ReduceLROnPlateau`) that reduces the learning rate when the validation loss plateaus.
	- This allows the improved model to be superior to the base network which uses SGD, as SGD requires careful tuning of the learning rate and momentum, while Adam automatically adapts the learning rate during training—often resulting in faster convergence and better overall performance.
5. Training Epochs & Batch size
	- The improved network trains for up to 20 epochs (with EarlyStopping potentially stopping earlier) using a smaller batch size of 32, which is typical when using data augmentation as it provides more frequent weight updates and can capture more nuanced variations in the data.
	- The base network trains for 10 epochs with a batch size of 64, which is less ideal than the improved network because a larger batch size with fewer epochs results in fewer weight updates and can limit the model’s ability to learn from the increased diversity provided by data augmentatio
6. Validation Strategy
	- The improved network separates the training data into dedicated training and validation sets using `train_test_split` to monitor performance more robustly during data augmentation.
	- The base network uses a built-in validation split of 20% from the training data which may not be as effective in monitoring performance under augmented data conditions.



### Training and Validation Loss vs Epochs
![loss vs epochs](img/q2/loss.png)

### Training and Validation Classification Accuracy vs Epochs

![accuracy vs epochs](img/q2/accuracy.png)

### Test Accuracy

After training the model, it was evaluated with the test set.

![test accuracy](img/q2/test.png)

Through the improvements, the test accuracy increased from 0.9714 to 0.9847.

## Q4 Using self created encoding

### PCA visualization


### Visualizing result from K-means clustering


### t-SNE visualization

### Visually inspecting clusters

### Summary of observations

